{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23a0ddda-3301-45ca-bb39-cc20b94ec11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659f292b-1f5a-4b4b-a504-5d78470df0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb3b2c0-d8b1-4b1e-8457-a26892da76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "182668fa-3be6-4a80-8b29-0c06d170d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dict = load_dataset(\"shawhin/phishing-site-classification\")\n",
    "dataset_file = \"C:\\\\Users\\\\Spandan\\\\Downloads\\\\Compressed\\\\Sentence Types - Question, Command and Statement\\\\Sentence Types - Question, Command and Statement.csv\"\n",
    "model_export_path = \"D:\\PROJECTS\\TensorFlow Model Exports\\LSTM Complex Question Detection\\lstm_model_complex_768_pre_padding.h5\"\n",
    "lr = 2e-4\n",
    "batch_size = 8\n",
    "num_epochs = 5\n",
    "dataset_size = 1000\n",
    "\n",
    "model_path = \"google-bert/bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1566151e-638c-4db9-bfe7-9ef48e87800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50aa1f2d-8562-43b5-9156-0c90e3382462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns = [\"text\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad948212-97e2-4cf7-97af-9a090c2c72f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['command', 'statement', 'question'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54db7472-cd30-4202-8805-aa219c2abb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "question     130655\n",
       "statement     78479\n",
       "command         932\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66331097-6d03-4e48-b596-5c376400beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.loc[df_raw[\"labels\"] != \"command\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48b0750a-291a-45c8-a10c-cbc25f259d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209134"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e142949-22b6-4681-a303-4caf033ea853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "question     130655\n",
       "statement     78479\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd6871be-9e1c-4a84-8cd6-6c0eb805b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spandan\\AppData\\Local\\Temp\\ipykernel_18236\\4010319830.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"labels\"] = df[\"labels\"].map(lambda typ: 0 if typ==\"statement\" else 1)\n"
     ]
    }
   ],
   "source": [
    "df[\"labels\"] = df[\"labels\"].map(lambda typ: 0 if typ==\"statement\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3289327-2cc7-4ed3-89de-ae71b1bf1578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's from Birmingham to em London Euston please</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the 8th of October</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i'd like to leave on the 7:33 train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there's the 7:33 from Birmingham New Street</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i'm just going to check to see what's your che...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "1   it's from Birmingham to em London Euston please        0\n",
       "2                                the 8th of October        0\n",
       "3               i'd like to leave on the 7:33 train        0\n",
       "4       there's the 7:33 from Birmingham New Street        0\n",
       "5  i'm just going to check to see what's your che...       0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ba30fd9-c64f-4aff-b22d-c10be1a66ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df = df.loc[df[\"labels\"] == 1]\n",
    "statement_df = df.loc[df[\"labels\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c62f7bd3-1558-4bdf-b200-5b1067997f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78479"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_size = min(len(question_df), len(statement_df))\n",
    "min_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b69e618-d2ef-4bd8-9e71-aed875c12370",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df = question_df.iloc[:min_size]\n",
    "statement_df = statement_df.iloc[:min_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6d3a7c3-b6b5-4b73-b2c9-dc0ac447507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78479\n",
      "78479\n"
     ]
    }
   ],
   "source": [
    "print(len(question_df))\n",
    "print(len(statement_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc28bef5-b44f-497e-90af-a4c62c85bdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>is that Birmingham New Street</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>do you hold a current debit or credit card</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>do you have a rail card</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>would you like smoking or non-smoking</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>and  do you have any seat preference</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text  labels\n",
       "42               is that Birmingham New Street        1\n",
       "43  do you hold a current debit or credit card        1\n",
       "44                     do you have a rail card        1\n",
       "45       would you like smoking or non-smoking        1\n",
       "46        and  do you have any seat preference        1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([question_df, statement_df], axis = 0)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bdfb9b6-f797-4ef5-9c2b-6fb46ddca8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78479, 2)\n",
      "(156958, 2)\n"
     ]
    }
   ],
   "source": [
    "print(question_df.shape)\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9d9ad34-8259-4869-9b67-0543f06b0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3d032c6-8a3f-4fbe-b26d-63aefa286318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    78479\n",
       "1    78479\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1493f71c-2385-44a9-96a6-eae3cc1dbb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = merged_df.iloc[:dataset_size]\n",
    "df_small = df_small.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d63c4988-f1dd-44ca-beda-dc4096411f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    526\n",
       "1    474\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1103fa67-935b-4622-8095-0182d56bbb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2180bc5f-5f1b-40dd-bf38-8e1968ca9967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moreover, facing a German military advance, L...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The RICO Act is still used today for all orga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If all three parameters are used, they are spe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Xbox 360 launched with 14 games in North A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Like the other groups, examples of their musi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0   Moreover, facing a German military advance, L...       0\n",
       "1   The RICO Act is still used today for all orga...       0\n",
       "2  If all three parameters are used, they are spe...       1\n",
       "3  The Xbox 360 launched with 14 games in North A...       1\n",
       "4   Like the other groups, examples of their musi...       0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83ad5e57-ecac-4562-a9ca-ebb9310aa3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df_small).train_test_split(test_size=0.10)\n",
    "# dataset_train_and_validation = dataset[\"train\"].train_test_split(test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90a3ad6c-64a2-4496-8ac3-7187058aeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\"train\": dataset[\"train\"], \"validation\": dataset[\"test\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b79061fc-004f-4f58-a70f-df13bd374e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74af24d8-7886-4824-a907-4900b083403f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    478\n",
       "1    422\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict[\"train\"].to_pandas().labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3a2ae5b-f050-4dfc-8f1a-6e9fdb0156a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dict[\"test\"].to_pandas().labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98fda20d-f229-467b-9908-d09b58bc75fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['What dictated that when a parent could not contract a legal marriage, offspring would follow the father',\n",
       "  \" Additionally, the media occasionally discusses the idea that Scotland's two biggest teams, Celtic and Rangers, should or will take part in the Premier League, but nothing has come of these discussions.\",\n",
       "  ' Other notable duck-producing countries in the Far East include Vietnam, Thailand, Malaysia, Myanmar, Indonesia and South Korea (12% in total).',\n",
       "  'When did the British claim Queen Elizabeth Land in Antarctica?',\n",
       "  ' After melting, homogenization and refining (removal of bubbles), the glass is formed.',\n",
       "  ' They disagreed with one another concerning the presence of Christ and his body and blood in Holy Communion.',\n",
       "  \" These urban foxes are noticeably bolder than their country cousins, sharing the pavement with pedestrians and raising cubs in people's backyards.\",\n",
       "  'At about the same time, Charles Coffin, leading the Thomson-Houston Electric Company, acquired a number of competitors and gained access to their key patents. In which US state was GE incorporated',\n",
       "  'Why did Chopin want his body opened when he died?',\n",
       "  ' The human brain is provided with information about light, sound, the chemical composition of the atmosphere, temperature, head orientation, limb position, the chemical composition of the bloodstream, and more'],\n",
       " 'labels': [1, 0, 0, 1, 0, 0, 0, 1, 1, 0]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "606bfb06-c0c9-4c87-a4e4-087e7378291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "vocabulary_size = 30522\n",
    "embedding_dimension = 768\n",
    "# min_len = 3\n",
    "# load model with binary classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f05aa19-4158-44ee-9443-6154fb9e4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, embedding_dimension, input_length=embedding_dimension))\n",
    "    model.add(LSTM(128,activation='relu',return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4544748b-d5e3-43e0-9b33-378fb204bc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 768, 768)          23440896  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 768, 128)          459264    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 768, 128)          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,035,905\n",
      "Trainable params: 24,035,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3158243c-dd02-41dd-89e9-f57353701a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████| 900/900 [00:00<00:00, 6682.01 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 5233.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# define text preprocessing\n",
    "def preprocess_function(examples):\n",
    "    # return tokenized text with truncation\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "    # return tokenizer(examples[\"text\"], truncation=False)\n",
    "\n",
    "#padded_dataset = sequence.pad_sequences(X_train, maxlen=min_len)\n",
    "# preprocess all datasets\n",
    "tokenized_data_raw = dataset_dict.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4dbdf664-5cf0-4da1-aa10-eaa6c2a9db4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8b17457-0851-4b73-bc14-5aa60a290293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What dictated that when a parent could not con...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2054, 23826, 2008, 2043, 1037, 6687, 207...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Additionally, the media occasionally discusse...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 5678, 1010, 1996, 2865, 5681, 15841, 199...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other notable duck-producing countries in the...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2060, 3862, 9457, 1011, 5155, 3032, 1999...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When did the British claim Queen Elizabeth Lan...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2043, 2106, 1996, 2329, 4366, 3035, 3870...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After melting, homogenization and refining (r...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2044, 13721, 1010, 24004, 6914, 3989, 19...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels  \\\n",
       "0  What dictated that when a parent could not con...       1   \n",
       "1   Additionally, the media occasionally discusse...       0   \n",
       "2   Other notable duck-producing countries in the...       0   \n",
       "3  When did the British claim Queen Elizabeth Lan...       1   \n",
       "4   After melting, homogenization and refining (r...       0   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 2054, 23826, 2008, 2043, 1037, 6687, 207...   \n",
       "1  [101, 5678, 1010, 1996, 2865, 5681, 15841, 199...   \n",
       "2  [101, 2060, 3862, 9457, 1011, 5155, 3032, 1999...   \n",
       "3  [101, 2043, 2106, 1996, 2329, 4366, 3035, 3870...   \n",
       "4  [101, 2044, 13721, 1010, 24004, 6914, 3989, 19...   \n",
       "\n",
       "                                      token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = tokenized_data_raw[\"train\"].to_pandas()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8059f38-1aa2-497e-886d-b67017442fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.asarray(sequence.pad_sequences(df_train[\"input_ids\"], maxlen=embedding_dimension, padding='pre')) # Post gives bad result\n",
    "target_data = np.asarray(df_train[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ea4dbe73-0d8f-4d4e-b35b-bdb0c73d24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_data_padded = DatasetDict(tokenized_data_padded)\n",
    "# tokenized_data_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "fd37a7fd-af34-4d01-8dc5-aab033b6a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = tokenized_data_padded[\"train\"]\n",
    "# testing_data = tokenized_data_padded[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9725e8ec-bbbc-45d4-9d62-de8916ff6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "647ddef3-2019-4fe7-85a0-86dd9342a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_data[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ce54b2c-3745-4440-b9cc-9e9f84729291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "auc_score = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # get predictions\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # apply softmax to get probabilities\n",
    "    probabilities = np.exp(predictions) / np.exp(predictions).sum(-1, \n",
    "                                                                 keepdims=True)\n",
    "    # use probabilities of the positive class for ROC AUC\n",
    "    positive_class_probs = probabilities[:, 1]\n",
    "    # compute auc\n",
    "    auc = np.round(auc_score.compute(prediction_scores=positive_class_probs, \n",
    "                                     references=labels)['roc_auc'],3)\n",
    "    \n",
    "    # predict most probable class\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    # compute accuracy\n",
    "    acc = np.round(accuracy.compute(predictions=predicted_classes, \n",
    "                                     references=labels)['accuracy'],3)\n",
    "    \n",
    "    return {\"Accuracy\": acc, \"AUC\": auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f083512-7970-44d6-9fde-385e0cbe0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, target_data, test_size=0.2, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f8ce304-207d-46a5-a62c-55980dee9193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 3094, 1029,  102],\n",
       "       [   0,    0,    0, ..., 2124, 2004,  102],\n",
       "       [   0,    0,    0, ..., 2377, 1029,  102],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1000, 1007,  102],\n",
       "       [   0,    0,    0, ..., 2069, 2051,  102],\n",
       "       [   0,    0,    0, ..., 2449, 3908,  102]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e9b4da6-d31b-4d8d-837f-a891fdaeb90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "90/90 [==============================] - 396s 4s/step - loss: nan - accuracy: 0.5681 \n",
      "Epoch 2/5\n",
      "87/90 [============================>.] - ETA: 13s - loss: nan - accuracy: 0.5273 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "074f4e03-48fc-48c9-b931-3cc4027be27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_model(model, model_location):\n",
    "#     save_classifier = open(model_location, \"wb\")\n",
    "#     pickle.dump(model, save_classifier)\n",
    "#     save_classifier.close()\n",
    "\n",
    "# def load_trained_model(model_location):\n",
    "#     loaded_model = load_model(model_location)\n",
    "#     return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "f47410a9-a16e-4b87-a0da-0da414ced4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(model, model_export_path)\n",
    "model.save_weights(model_export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "453fd631-bcc2-4516-a7c5-1af76d7ed5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_loaded = load_trained_model(model_export_path)\n",
    "loaded_model = create_model()\n",
    "loaded_model.load_weights(model_export_path)\n",
    "# with open(model_export_path, 'rb') as file:\n",
    "#     model_loaded = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6d7d9b3b-6398-4298-a51b-52fc63436164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  1997, 26315,   102],\n",
       "       [    0,     0,     0, ...,  2942,  4812,   102],\n",
       "       [    0,     0,     0, ..., 14000,  1012,   102],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  1055,  2171,   102],\n",
       "       [    0,     0,     0, ...,  2320,  1012,   102],\n",
       "       [    0,     0,     0, ...,  6153,  8223,   102]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "672524a7-af8d-4cc0-8b8e-a78988e9da39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 96ms/step\n",
      "180\n",
      "180\n",
      "0.5777777777777777\n"
     ]
    }
   ],
   "source": [
    "# apply model to validation dataset\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# Extract the logits and labels fr\n",
    "pred_0_1 = np.array([[0 if pred<0.5 else 1] for pred in predictions])\n",
    "\n",
    "print(len(pred_0_1))\n",
    "print(len(y_test))\n",
    "# Use your compute_metrics function\n",
    "accuracy = accuracy_score(y_test, pred_0_1)\n",
    "# metrics = compute_metrics((logits, labels))\n",
    "print(accuracy)\n",
    "\n",
    "# BERT {'Accuracy': 0.955, 'AUC': 0.989}\n",
    "#DistilBERT {'Accuracy': 0.944, 'AUC': 0.994}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7387b06f-6b64-45d1-9bc0-aa75eeec7a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[104,  76],\n",
       "       [  0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pred_0_1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "996388c7-a83d-4c50-8777-3cd7a8a25397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_text_single(text):\n",
    "    # return tokenized text with truncation\n",
    "    ebmedding = [tokenizer(text, truncation=True)[\"input_ids\"]]\n",
    "    # print(x)\n",
    "    return np.asarray(sequence.pad_sequences(ebmedding, maxlen=embedding_dimension, padding='post'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "21f5e112-2cec-4312-b889-a3384f1eb9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "10413eb8-533a-482c-a79d-d55242023fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"What developed from the mammalian odor pathways?\"\n",
    "sentence = \"Could you please tell me the direction of the retaurant?\"\n",
    "sentence = \"How do you know this?\"\n",
    "tokenized_question = tokenizer_text_single(sentence)\n",
    "tokenized_question[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8218e39b-ec8b-46e5-954b-2f04efb3ff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9999062]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = loaded_model.predict([tokenized_question])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8119f58d-2c69-4fe4-8f5f-35ef878868f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Burke received a vote of thanks from the Commons for his services in the Hastings Trial and he immediately resigned his seat\"\n",
    "tokenized_question = tokenizer_text_single(sentence)\n",
    "tokenized_question[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0ca2942a-8408-4aff-9542-ac891ba07649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00389195]], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = loaded_model.predict([tokenized_question])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "84b2753a-b5a8-46f5-8cfb-30a6deaa23e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156958"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_test = merged_df.sample(frac=1).reset_index(drop=True)\n",
    "len(merged_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "59891f36-82c3-48d5-966d-763cbef524c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The following year, it chartered the Royal Ni...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of data compression is the converse ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film was another huge box office smash, g...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raised in Chicago, West briefly attended art s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's a Super Saver return i think i need</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels  \\\n",
       "0   The following year, it chartered the Royal Ni...       0   \n",
       "1  What type of data compression is the converse ...       1   \n",
       "2   The film was another huge box office smash, g...       0   \n",
       "3  Raised in Chicago, West briefly attended art s...       1   \n",
       "4          it's a Super Saver return i think i need        0   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25bab6c-ccac-4a73-860b-e2491a16d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_function_df(examples):\n",
    "#     # return tokenized text with truncation\n",
    "#     return tokenizer(examples[\"text\"], truncation=True)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "057084d0-245b-42f6-a296-fd0218806d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_text_df(text):\n",
    "    # return tokenized text with truncation\n",
    "    ebmedding = tokenizer(text, truncation=True)[\"input_ids\"]\n",
    "    return ebmedding\n",
    "    # print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "3b0da50c-3ad9-47be-aeeb-ddde67737899",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`sequences` must be a list of iterables. Found non-iterable: 101",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\keras\\utils\\data_utils.py:1043\u001b[0m, in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m     lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flag \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x):\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[390], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized_data \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_text_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# merged_df_test_embeddings = np.asarray(sequence.pad_sequences(tokenized_data, maxlen=embedding_dimension, padding='pre'))\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[389], line 6\u001b[0m, in \u001b[0;36mtokenizer_text_df\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m ebmedding \u001b[38;5;241m=\u001b[39m tokenizer(text, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# return ebmedding\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# print(x)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mebmedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\keras\\utils\\data_utils.py:1048\u001b[0m, in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1048\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1049\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sequences` must be a list of iterables. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1050\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound non-iterable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1051\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1054\u001b[0m     maxlen \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(lengths)\n",
      "\u001b[1;31mValueError\u001b[0m: `sequences` must be a list of iterables. Found non-iterable: 101"
     ]
    }
   ],
   "source": [
    "tokenized_data = merged_df_test[\"text\"].apply(tokenizer_text_df)\n",
    "# merged_df_test_embeddings = np.asarray(sequence.pad_sequences(tokenized_data, maxlen=embedding_dimension, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "8a1d5b9c-134a-4bf5-834b-32c8d14f77ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [101, 1996, 2206, 2095, 1010, 2009, 12443, 199...\n",
       "1         [101, 2054, 2828, 1997, 2951, 13379, 2003, 199...\n",
       "2         [101, 1996, 2143, 2001, 2178, 4121, 3482, 2436...\n",
       "3         [101, 2992, 1999, 3190, 1010, 2225, 4780, 3230...\n",
       "4         [101, 2009, 1005, 1055, 1037, 3565, 3828, 2099...\n",
       "                                ...                        \n",
       "156953    [101, 2574, 1010, 2474, 6633, 19968, 2063, 199...\n",
       "156954    [101, 1996, 2744, 1000, 7680, 27549, 1000, 200...\n",
       "156955    [101, 2043, 2106, 7072, 2991, 1999, 6956, 1997...\n",
       "156956    [101, 1999, 3655, 2060, 2084, 4199, 1010, 1996...\n",
       "156957    [101, 5709, 22975, 2546, 1997, 3019, 3806, 100...\n",
       "Name: text, Length: 156958, dtype: object"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "afaae1e5-2dea-471e-ac20-0a2a4af341ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_encoding_test = sequence.pad_sequences(tokenized_data, maxlen=embedding_dimension, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "8f0fa3d9-4dee-43d2-8237-645fa2cbd631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  2751,  2666,   102],\n",
       "       [    0,     0,     0, ..., 11259,  8358,   102],\n",
       "       [    0,     0,     0, ...,  4969,  1012,   102],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  3354,  2586,   102],\n",
       "       [    0,     0,     0, ...,  8170,  1029,   102],\n",
       "       [    0,     0,     0, ...,  3088,  1012,   102]])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_encoding_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "b8766ede-a948-4046-a1fe-43a5fb872a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_test[\"embedding1d\"] = padded_encoding_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "78222a31-dd94-453e-b677-528da55d68a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embedding1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The following year, it chartered the Royal Ni...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of data compression is the converse ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film was another huge box office smash, g...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raised in Chicago, West briefly attended art s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's a Super Saver return i think i need</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels  \\\n",
       "0   The following year, it chartered the Royal Ni...       0   \n",
       "1  What type of data compression is the converse ...       1   \n",
       "2   The film was another huge box office smash, g...       0   \n",
       "3  Raised in Chicago, West briefly attended art s...       1   \n",
       "4          it's a Super Saver return i think i need        0   \n",
       "\n",
       "                                          embeddings  embedding1d  \n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...            0  \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...            0  \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...            0  \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...            0  \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...            0  "
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "f5ea0ab0-9c40-47ba-b5c5-5c59beedebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_encoding_test_10k = padded_encoding_test[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "1c460fa2-5b69-42d9-b11e-8ef4fc67b3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_encoding_test_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "ac03ea5c-07e5-432b-8335-f294719596a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  2751,  2666,   102],\n",
       "       [    0,     0,     0, ..., 11259,  8358,   102],\n",
       "       [    0,     0,     0, ...,  4969,  1012,   102],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  1996,  7095,   102],\n",
       "       [    0,     0,     0, ...,  1996,  2479,   102],\n",
       "       [    0,     0,     0, ...,  1997,  3163,   102]])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_encoding_test_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "1b892c38-cc96-415d-a70b-dea86afbd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.asarray(merged_df_test_10k[\"embeddings\"][0]).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "ef82873a-d448-41ef-b80a-f46a3d4a79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "009c91b5-211a-4e1f-9f88-40bc68a126df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 19s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "##### Time \n",
    "from time import time\n",
    "start_time = time()\n",
    "loaded_model.predict(padded_encoding_test_10k)\n",
    "end_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "beaefb51-60a9-4f55-b417-11d5a38f8545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.372161388397217"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_diff = end_time - start_time\n",
    "time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1101e5d-cf95-4fa7-873f-44ed3716da84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_cuda",
   "language": "python",
   "name": "ml_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "23a0ddda-3301-45ca-bb39-cc20b94ec11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "659f292b-1f5a-4b4b-a504-5d78470df0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "bbb3b2c0-d8b1-4b1e-8457-a26892da76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "182668fa-3be6-4a80-8b29-0c06d170d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dict = load_dataset(\"shawhin/phishing-site-classification\")\n",
    "dataset_file = \"C:\\\\Users\\\\Spandan\\\\Downloads\\\\Compressed\\\\Sentence Types - Question, Command and Statement\\\\Sentence Types - Question, Command and Statement.csv\"\n",
    "model_export_path = \"D:\\PROJECTS\\TensorFlow Model Exports\\LSTM Simple Question Detection\\\\lstm_model_768_pre_padding.h5\"\n",
    "lr = 2e-4\n",
    "batch_size = 8\n",
    "num_epochs = 5\n",
    "dataset_size = 1000\n",
    "\n",
    "model_path = \"google-bert/bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1566151e-638c-4db9-bfe7-9ef48e87800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "50aa1f2d-8562-43b5-9156-0c90e3382462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns = [\"text\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "ad948212-97e2-4cf7-97af-9a090c2c72f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['command', 'statement', 'question'], dtype=object)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "54db7472-cd30-4202-8805-aa219c2abb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "question     130655\n",
       "statement     78479\n",
       "command         932\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "66331097-6d03-4e48-b596-5c376400beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.loc[df_raw[\"labels\"] != \"command\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "48b0750a-291a-45c8-a10c-cbc25f259d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209134"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "7e142949-22b6-4681-a303-4caf033ea853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "question     130655\n",
       "statement     78479\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "fd6871be-9e1c-4a84-8cd6-6c0eb805b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spandan\\AppData\\Local\\Temp\\ipykernel_14924\\4010319830.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"labels\"] = df[\"labels\"].map(lambda typ: 0 if typ==\"statement\" else 1)\n"
     ]
    }
   ],
   "source": [
    "df[\"labels\"] = df[\"labels\"].map(lambda typ: 0 if typ==\"statement\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "d3289327-2cc7-4ed3-89de-ae71b1bf1578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's from Birmingham to em London Euston please</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the 8th of October</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i'd like to leave on the 7:33 train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there's the 7:33 from Birmingham New Street</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i'm just going to check to see what's your che...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "1   it's from Birmingham to em London Euston please        0\n",
       "2                                the 8th of October        0\n",
       "3               i'd like to leave on the 7:33 train        0\n",
       "4       there's the 7:33 from Birmingham New Street        0\n",
       "5  i'm just going to check to see what's your che...       0"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "7ba30fd9-c64f-4aff-b22d-c10be1a66ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df = df.loc[df[\"labels\"] == 1]\n",
    "statement_df = df.loc[df[\"labels\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "c62f7bd3-1558-4bdf-b200-5b1067997f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78479"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_size = min(len(question_df), len(statement_df))\n",
    "min_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "0b69e618-d2ef-4bd8-9e71-aed875c12370",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df = question_df.iloc[:min_size]\n",
    "statement_df = statement_df.iloc[:min_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a6d3a7c3-b6b5-4b73-b2c9-dc0ac447507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78479\n",
      "78479\n"
     ]
    }
   ],
   "source": [
    "print(len(question_df))\n",
    "print(len(statement_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "dc28bef5-b44f-497e-90af-a4c62c85bdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>is that Birmingham New Street</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>do you hold a current debit or credit card</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>do you have a rail card</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>would you like smoking or non-smoking</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>and  do you have any seat preference</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text  labels\n",
       "42               is that Birmingham New Street        1\n",
       "43  do you hold a current debit or credit card        1\n",
       "44                     do you have a rail card        1\n",
       "45       would you like smoking or non-smoking        1\n",
       "46        and  do you have any seat preference        1"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([question_df, statement_df], axis = 0)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "1bdfb9b6-f797-4ef5-9c2b-6fb46ddca8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78479, 2)\n",
      "(156958, 2)\n"
     ]
    }
   ],
   "source": [
    "print(question_df.shape)\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "c9d9ad34-8259-4869-9b67-0543f06b0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a3d032c6-8a3f-4fbe-b26d-63aefa286318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    78479\n",
       "1    78479\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "1493f71c-2385-44a9-96a6-eae3cc1dbb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = merged_df.iloc[:dataset_size]\n",
    "df_small = df_small.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "d63c4988-f1dd-44ca-beda-dc4096411f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    518\n",
       "1    482\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "1103fa67-935b-4622-8095-0182d56bbb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "2180bc5f-5f1b-40dd-bf38-8e1968ca9967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thus, the popular association of infrared rad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For Kanye to make an album called College Dro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>More advanced memory management chips (MMC) s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pilot Mountain and South Mountains are located...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most records at NARA are in the public domain,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0   Thus, the popular association of infrared rad...       0\n",
       "1   For Kanye to make an album called College Dro...       0\n",
       "2   More advanced memory management chips (MMC) s...       0\n",
       "3  Pilot Mountain and South Mountains are located...       1\n",
       "4  Most records at NARA are in the public domain,...       0"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "83ad5e57-ecac-4562-a9ca-ebb9310aa3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df_small).train_test_split(test_size=0.10)\n",
    "# dataset_train_and_validation = dataset[\"train\"].train_test_split(test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "90a3ad6c-64a2-4496-8ac3-7187058aeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\"train\": dataset[\"train\"], \"validation\": dataset[\"test\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "b79061fc-004f-4f58-a70f-df13bd374e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "74af24d8-7886-4824-a907-4900b083403f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    470\n",
       "1    430\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict[\"train\"].to_pandas().labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "e3a2ae5b-f050-4dfc-8f1a-6e9fdb0156a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dict[\"test\"].to_pandas().labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "98fda20d-f229-467b-9908-d09b58bc75fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': [' The sexual haploid phase of embryophytes, known as the gametophyte, nurtures the developing diploid embryo sporophyte within its tissues for at least part of its life, even in the seed plants, where the gametophyte itself is nurtured by its parent sporophyte',\n",
       "  'Why were flights delayed and diverted',\n",
       "  'Which Late Middle Age English kings kept their own troupes of professional actors?',\n",
       "  ' in 2014, a 260% increase since 2009.',\n",
       "  \" In 1169, as the Kievan Rus' state was full of internal conflict, Andrei Bogolyubsky of Vladimir sacked the city of Kiev\",\n",
       "  ' The city subsidises an organisation for amateur education in arts aimed at all inhabitants (Utrechts Centrum voor de Kunsten), as does the university for its staff and students.',\n",
       "  \"Jackson's TAV Music merged with whom?\",\n",
       "  'In Indian philosophy, Yoga is among other things, the name of one of the six āstika philosophical schools. What concept does yoga accept the differentiates it from Samkhya',\n",
       "  \"The British high-definition TV service started trials in August 1936 and a regular service on 2 November 1936 using both the (mechanical) Baird 240 line sequential scan (later to be inaccurately rechristened 'progressive') and the (electronic) Marconi-EMI 405 line interlaced systems.  When was the Baird system created?\",\n",
       "  ' The Iranian Parliament has been showing disregard for wildlife by passing laws and regulations such as the act that lets the Ministry of Industries and Mines exploit mines without the involvement of the Department of Environment, and by approving large national development projects without demanding comprehensive study of their impact on wildlife habitats'],\n",
       " 'labels': [0, 1, 1, 0, 0, 0, 1, 1, 1, 0]}"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "606bfb06-c0c9-4c87-a4e4-087e7378291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "vocabulary_size = 30522\n",
    "embedding_dimension = 768\n",
    "# min_len = 3\n",
    "# load model with binary classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "4f05aa19-4158-44ee-9443-6154fb9e4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, embedding_dimension, input_length=embedding_dimension))\n",
    "    model.add(LSTM(100)) #Can be same as embedding_dimension, but model will large and inefficient\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "4544748b-d5e3-43e0-9b33-378fb204bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "7d981702-e3c5-4fa7-9fd0-61d147c17334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "e1ebe16d-0c3c-4386-a38a-1577c920798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [name for name, param in model.base_model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a7a93-6e43-492c-b9b5-f7a67c07d08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "3158243c-dd02-41dd-89e9-f57353701a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████| 900/900 [00:00<00:00, 10614.79 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 4492.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# define text preprocessing\n",
    "def preprocess_function(examples):\n",
    "    # return tokenized text with truncation\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "    # return tokenizer(examples[\"text\"], truncation=False)\n",
    "\n",
    "#padded_dataset = sequence.pad_sequences(X_train, maxlen=min_len)\n",
    "# preprocess all datasets\n",
    "tokenized_data_raw = dataset_dict.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "4dbdf664-5cf0-4da1-aa10-eaa6c2a9db4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "e8b17457-0851-4b73-bc14-5aa60a290293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sexual haploid phase of embryophytes, kno...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1996, 4424, 5292, 24759, 9314, 4403, 199...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why were flights delayed and diverted</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2339, 2020, 7599, 8394, 1998, 18356, 102]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which Late Middle Age English kings kept their...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2029, 2397, 2690, 2287, 2394, 5465, 2921...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in 2014, a 260% increase since 2009.</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1999, 2297, 1010, 1037, 13539, 1003, 362...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In 1169, as the Kievan Rus' state was full of...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1999, 12904, 2683, 1010, 2004, 1996, 121...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels  \\\n",
       "0   The sexual haploid phase of embryophytes, kno...       0   \n",
       "1              Why were flights delayed and diverted       1   \n",
       "2  Which Late Middle Age English kings kept their...       1   \n",
       "3               in 2014, a 260% increase since 2009.       0   \n",
       "4   In 1169, as the Kievan Rus' state was full of...       0   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 1996, 4424, 5292, 24759, 9314, 4403, 199...   \n",
       "1    [101, 2339, 2020, 7599, 8394, 1998, 18356, 102]   \n",
       "2  [101, 2029, 2397, 2690, 2287, 2394, 5465, 2921...   \n",
       "3  [101, 1999, 2297, 1010, 1037, 13539, 1003, 362...   \n",
       "4  [101, 1999, 12904, 2683, 1010, 2004, 1996, 121...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1                           [1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = tokenized_data_raw[\"train\"].to_pandas()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "a8059f38-1aa2-497e-886d-b67017442fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.asarray(sequence.pad_sequences(df_train[\"input_ids\"], maxlen=embedding_dimension, padding='pre')) # Post gives bad result\n",
    "target_data = np.asarray(df_train[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "ea8fdb67-23fa-449a-9c20-b60a7b965573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "d8485896-6bf8-4dbd-9e48-38fdda4d38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pad_tokens(collection__):\n",
    "#     # return [sequence.pad_sequences([x[\"input_ids\"]], maxlen=embedding_dimension, padding='post')[0] for x in collection__]\n",
    "#     return [sequence.pad_sequences([x[\"input_ids\"]], maxlen=embedding_dimension, padding='post')[0] for x in collection__]\n",
    "# def pad_collection(coll):\n",
    "#     padded_tokens = {}\n",
    "#     for key, v in tokenized_data.items():\n",
    "#         padded_tokens[key] = []\n",
    "#         # print(key)\n",
    "#         mapped = pad_tokens(v)\n",
    "#         for m in mapped:\n",
    "#             # print(m)\n",
    "#             padded_tokens[key].append(m)\n",
    "#     return padded_tokens\n",
    "# padded = pad_tokens(tokenized_data_raw[\"train\"][0][\"input_ids\"])\n",
    "# padded = pad_tokens(tokenized_data_raw[\"train\"])\n",
    "# padded\n",
    "    # for x in v:\n",
    "    #     print(x[\"input_ids\"])\n",
    "    #     print(sequence.pad_sequences([x[\"input_ids\"]], maxlen=embedding_dimension, padding='post'))\n",
    "    # print(sequence.pad_sequences([v[0][\"input_ids\"]], maxlen=embedding_dimension, padding='post'))\n",
    "# tokenized_data_padded = tokenized_data.map(lambda ds: sequence.pad_sequences(ds[\"input_ids\"], maxlen=embedding_dimension, padding='post'))\n",
    "# tokenized_data_padded = tokenized_data.map(pad_tokens)\n",
    "# tokenized_data_padded\n",
    "# padded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "5affbad1-6fb0-4cb4-8dee-6806e3c9780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_data_padded = pad_collection(tokenized_data_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "401ed844-41db-4d13-a8e3-6b53367bfc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_data_raw[\"test\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ea4dbe73-0d8f-4d4e-b35b-bdb0c73d24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_data_padded = DatasetDict(tokenized_data_padded)\n",
    "# tokenized_data_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "fd37a7fd-af34-4d01-8dc5-aab033b6a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = tokenized_data_padded[\"train\"]\n",
    "# testing_data = tokenized_data_padded[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9725e8ec-bbbc-45d4-9d62-de8916ff6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "647ddef3-2019-4fe7-85a0-86dd9342a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_data[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "0ce54b2c-3745-4440-b9cc-9e9f84729291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "auc_score = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # get predictions\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # apply softmax to get probabilities\n",
    "    probabilities = np.exp(predictions) / np.exp(predictions).sum(-1, \n",
    "                                                                 keepdims=True)\n",
    "    # use probabilities of the positive class for ROC AUC\n",
    "    positive_class_probs = probabilities[:, 1]\n",
    "    # compute auc\n",
    "    auc = np.round(auc_score.compute(prediction_scores=positive_class_probs, \n",
    "                                     references=labels)['roc_auc'],3)\n",
    "    \n",
    "    # predict most probable class\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    # compute accuracy\n",
    "    acc = np.round(accuracy.compute(predictions=predicted_classes, \n",
    "                                     references=labels)['accuracy'],3)\n",
    "    \n",
    "    return {\"Accuracy\": acc, \"AUC\": auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "8f083512-7970-44d6-9fde-385e0cbe0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, target_data, test_size=0.2, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5f8ce304-207d-46a5-a62c-55980dee9193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  6687,  1012,   102],\n",
       "       [    0,     0,     0, ...,  8294,  1029,   102],\n",
       "       [    0,     0,     0, ...,  1997,  4331,   102],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  1998, 12546,   102],\n",
       "       [    0,     0,     0, ...,  3117,  1029,   102],\n",
       "       [    0,     0,     0, ...,  2217,  1012,   102]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "3e9b4da6-d31b-4d8d-837f-a891fdaeb90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "90/90 [==============================] - 12s 101ms/step - loss: 0.2881 - accuracy: 0.8833\n",
      "Epoch 2/5\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 0.0161 - accuracy: 0.9972\n",
      "Epoch 3/5\n",
      "90/90 [==============================] - 9s 100ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "90/90 [==============================] - 9s 98ms/step - loss: 3.1915e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "90/90 [==============================] - 9s 95ms/step - loss: 1.9630e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23ca428a9e0>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "074f4e03-48fc-48c9-b931-3cc4027be27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_model(model, model_location):\n",
    "#     save_classifier = open(model_location, \"wb\")\n",
    "#     pickle.dump(model, save_classifier)\n",
    "#     save_classifier.close()\n",
    "\n",
    "# def load_trained_model(model_location):\n",
    "#     loaded_model = load_model(model_location)\n",
    "#     return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "f47410a9-a16e-4b87-a0da-0da414ced4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(model, model_export_path)\n",
    "model.save_weights(model_export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "453fd631-bcc2-4516-a7c5-1af76d7ed5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_loaded = load_trained_model(model_export_path)\n",
    "loaded_model = create_model()\n",
    "loaded_model.load_weights(model_export_path)\n",
    "# with open(model_export_path, 'rb') as file:\n",
    "#     model_loaded = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6d7d9b3b-6398-4298-a51b-52fc63436164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  1997, 26315,   102],\n",
       "       [    0,     0,     0, ...,  2942,  4812,   102],\n",
       "       [    0,     0,     0, ..., 14000,  1012,   102],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  1055,  2171,   102],\n",
       "       [    0,     0,     0, ...,  2320,  1012,   102],\n",
       "       [    0,     0,     0, ...,  6153,  8223,   102]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "672524a7-af8d-4cc0-8b8e-a78988e9da39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 96ms/step\n",
      "180\n",
      "180\n",
      "0.5777777777777777\n"
     ]
    }
   ],
   "source": [
    "# apply model to validation dataset\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# Extract the logits and labels fr\n",
    "pred_0_1 = np.array([[0 if pred<0.5 else 1] for pred in predictions])\n",
    "\n",
    "print(len(pred_0_1))\n",
    "print(len(y_test))\n",
    "# Use your compute_metrics function\n",
    "accuracy = accuracy_score(y_test, pred_0_1)\n",
    "# metrics = compute_metrics((logits, labels))\n",
    "print(accuracy)\n",
    "\n",
    "# BERT {'Accuracy': 0.955, 'AUC': 0.989}\n",
    "#DistilBERT {'Accuracy': 0.944, 'AUC': 0.994}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7387b06f-6b64-45d1-9bc0-aa75eeec7a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[104,  76],\n",
       "       [  0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pred_0_1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "996388c7-a83d-4c50-8777-3cd7a8a25397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_text_single(text):\n",
    "    # return tokenized text with truncation\n",
    "    ebmedding = [tokenizer(text, truncation=True)[\"input_ids\"]]\n",
    "    # print(x)\n",
    "    return np.asarray(sequence.pad_sequences(ebmedding, maxlen=embedding_dimension, padding='post'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "21f5e112-2cec-4312-b889-a3384f1eb9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "10413eb8-533a-482c-a79d-d55242023fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"What developed from the mammalian odor pathways?\"\n",
    "sentence = \"Could you please tell me the direction of the retaurant?\"\n",
    "sentence = \"How do you know this?\"\n",
    "tokenized_question = tokenizer_text_single(sentence)\n",
    "tokenized_question[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8218e39b-ec8b-46e5-954b-2f04efb3ff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9999062]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = loaded_model.predict([tokenized_question])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8119f58d-2c69-4fe4-8f5f-35ef878868f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Burke received a vote of thanks from the Commons for his services in the Hastings Trial and he immediately resigned his seat\"\n",
    "tokenized_question = tokenizer_text_single(sentence)\n",
    "tokenized_question[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0ca2942a-8408-4aff-9542-ac891ba07649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00389195]], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = loaded_model.predict([tokenized_question])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "84b2753a-b5a8-46f5-8cfb-30a6deaa23e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156958"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_test = merged_df.sample(frac=1).reset_index(drop=True)\n",
    "len(merged_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "59891f36-82c3-48d5-966d-763cbef524c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The following year, it chartered the Royal Ni...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of data compression is the converse ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film was another huge box office smash, g...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raised in Chicago, West briefly attended art s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's a Super Saver return i think i need</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels  \\\n",
       "0   The following year, it chartered the Royal Ni...       0   \n",
       "1  What type of data compression is the converse ...       1   \n",
       "2   The film was another huge box office smash, g...       0   \n",
       "3  Raised in Chicago, West briefly attended art s...       1   \n",
       "4          it's a Super Saver return i think i need        0   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25bab6c-ccac-4a73-860b-e2491a16d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_function_df(examples):\n",
    "#     # return tokenized text with truncation\n",
    "#     return tokenizer(examples[\"text\"], truncation=True)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "057084d0-245b-42f6-a296-fd0218806d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_text_df(text):\n",
    "    # return tokenized text with truncation\n",
    "    ebmedding = tokenizer(text, truncation=True)[\"input_ids\"]\n",
    "    return ebmedding\n",
    "    # print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "3b0da50c-3ad9-47be-aeeb-ddde67737899",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`sequences` must be a list of iterables. Found non-iterable: 101",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\keras\\utils\\data_utils.py:1043\u001b[0m, in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m     lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flag \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x):\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[390], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized_data \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_text_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# merged_df_test_embeddings = np.asarray(sequence.pad_sequences(tokenized_data, maxlen=embedding_dimension, padding='pre'))\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[389], line 6\u001b[0m, in \u001b[0;36mtokenizer_text_df\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m ebmedding \u001b[38;5;241m=\u001b[39m tokenizer(text, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# return ebmedding\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# print(x)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mebmedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml_cuda\\lib\\site-packages\\keras\\utils\\data_utils.py:1048\u001b[0m, in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1048\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1049\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sequences` must be a list of iterables. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1050\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound non-iterable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1051\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1054\u001b[0m     maxlen \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(lengths)\n",
      "\u001b[1;31mValueError\u001b[0m: `sequences` must be a list of iterables. Found non-iterable: 101"
     ]
    }
   ],
   "source": [
    "tokenized_data = merged_df_test[\"text\"].apply(tokenizer_text_df)\n",
    "# merged_df_test_embeddings = np.asarray(sequence.pad_sequences(tokenized_data, maxlen=embedding_dimension, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "8a1d5b9c-134a-4bf5-834b-32c8d14f77ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [101, 1996, 2206, 2095, 1010, 2009, 12443, 199...\n",
       "1         [101, 2054, 2828, 1997, 2951, 13379, 2003, 199...\n",
       "2         [101, 1996, 2143, 2001, 2178, 4121, 3482, 2436...\n",
       "3         [101, 2992, 1999, 3190, 1010, 2225, 4780, 3230...\n",
       "4         [101, 2009, 1005, 1055, 1037, 3565, 3828, 2099...\n",
       "                                ...                        \n",
       "156953    [101, 2574, 1010, 2474, 6633, 19968, 2063, 199...\n",
       "156954    [101, 1996, 2744, 1000, 7680, 27549, 1000, 200...\n",
       "156955    [101, 2043, 2106, 7072, 2991, 1999, 6956, 1997...\n",
       "156956    [101, 1999, 3655, 2060, 2084, 4199, 1010, 1996...\n",
       "156957    [101, 5709, 22975, 2546, 1997, 3019, 3806, 100...\n",
       "Name: text, Length: 156958, dtype: object"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "afaae1e5-2dea-471e-ac20-0a2a4af341ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_encoding_test = sequence.pad_sequences(tokenized_data, maxlen=embedding_dimension, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "8f0fa3d9-4dee-43d2-8237-645fa2cbd631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  2751,  2666,   102],\n",
       "       [    0,     0,     0, ..., 11259,  8358,   102],\n",
       "       [    0,     0,     0, ...,  4969,  1012,   102],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  3354,  2586,   102],\n",
       "       [    0,     0,     0, ...,  8170,  1029,   102],\n",
       "       [    0,     0,     0, ...,  3088,  1012,   102]])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_encoding_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "b8766ede-a948-4046-a1fe-43a5fb872a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_test[\"embedding1d\"] = padded_encoding_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "78222a31-dd94-453e-b677-528da55d68a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embedding1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The following year, it chartered the Royal Ni...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of data compression is the converse ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film was another huge box office smash, g...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raised in Chicago, West briefly attended art s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's a Super Saver return i think i need</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels  \\\n",
       "0   The following year, it chartered the Royal Ni...       0   \n",
       "1  What type of data compression is the converse ...       1   \n",
       "2   The film was another huge box office smash, g...       0   \n",
       "3  Raised in Chicago, West briefly attended art s...       1   \n",
       "4          it's a Super Saver return i think i need        0   \n",
       "\n",
       "                                          embeddings  embedding1d  \n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...            0  \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...            0  \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...            0  \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...            0  \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...            0  "
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "f5ea0ab0-9c40-47ba-b5c5-5c59beedebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_encoding_test_10k = padded_encoding_test[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "1c460fa2-5b69-42d9-b11e-8ef4fc67b3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_encoding_test_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "ac03ea5c-07e5-432b-8335-f294719596a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  2751,  2666,   102],\n",
       "       [    0,     0,     0, ..., 11259,  8358,   102],\n",
       "       [    0,     0,     0, ...,  4969,  1012,   102],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  1996,  7095,   102],\n",
       "       [    0,     0,     0, ...,  1996,  2479,   102],\n",
       "       [    0,     0,     0, ...,  1997,  3163,   102]])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_encoding_test_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "1b892c38-cc96-415d-a70b-dea86afbd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.asarray(merged_df_test_10k[\"embeddings\"][0]).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "ef82873a-d448-41ef-b80a-f46a3d4a79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "009c91b5-211a-4e1f-9f88-40bc68a126df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 19s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "##### Time \n",
    "from time import time\n",
    "start_time = time()\n",
    "loaded_model.predict(padded_encoding_test_10k)\n",
    "end_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "beaefb51-60a9-4f55-b417-11d5a38f8545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.372161388397217"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_diff = end_time - start_time\n",
    "time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1101e5d-cf95-4fa7-873f-44ed3716da84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_cuda",
   "language": "python",
   "name": "ml_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

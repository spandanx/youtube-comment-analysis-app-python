{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "23a0ddda-3301-45ca-bb39-cc20b94ec11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659f292b-1f5a-4b4b-a504-5d78470df0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb3b2c0-d8b1-4b1e-8457-a26892da76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "182668fa-3be6-4a80-8b29-0c06d170d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dict = load_dataset(\"shawhin/phishing-site-classification\")\n",
    "dataset_file = \"C:\\\\Users\\\\Spandan\\\\Downloads\\\\Compressed\\\\Sentence Types - Question, Command and Statement\\\\Sentence Types - Question, Command and Statement.csv\"\n",
    "model_export_path = \"D:\\PROJECTS\\TensorFlow Model Exports\\LSTM Simple Question Detection\\\\lstm_model_768.h5\"\n",
    "lr = 2e-4\n",
    "batch_size = 8\n",
    "num_epochs = 5\n",
    "dataset_size = 1000\n",
    "\n",
    "# define pre-trained model path\n",
    "model_path = \"distilbert/distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1566151e-638c-4db9-bfe7-9ef48e87800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50aa1f2d-8562-43b5-9156-0c90e3382462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns = [\"text\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad948212-97e2-4cf7-97af-9a090c2c72f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['command', 'statement', 'question'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54db7472-cd30-4202-8805-aa219c2abb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "question     130655\n",
       "statement     78479\n",
       "command         932\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66331097-6d03-4e48-b596-5c376400beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.loc[df_raw[\"labels\"] != \"command\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48b0750a-291a-45c8-a10c-cbc25f259d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209134"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e142949-22b6-4681-a303-4caf033ea853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "question     130655\n",
       "statement     78479\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd6871be-9e1c-4a84-8cd6-6c0eb805b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spandan\\AppData\\Local\\Temp\\ipykernel_18612\\4010319830.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"labels\"] = df[\"labels\"].map(lambda typ: 0 if typ==\"statement\" else 1)\n"
     ]
    }
   ],
   "source": [
    "df[\"labels\"] = df[\"labels\"].map(lambda typ: 0 if typ==\"statement\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3289327-2cc7-4ed3-89de-ae71b1bf1578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's from Birmingham to em London Euston please</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the 8th of October</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i'd like to leave on the 7:33 train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there's the 7:33 from Birmingham New Street</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i'm just going to check to see what's your che...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "1   it's from Birmingham to em London Euston please        0\n",
       "2                                the 8th of October        0\n",
       "3               i'd like to leave on the 7:33 train        0\n",
       "4       there's the 7:33 from Birmingham New Street        0\n",
       "5  i'm just going to check to see what's your che...       0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ba30fd9-c64f-4aff-b22d-c10be1a66ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df = df.loc[df[\"labels\"] == 1]\n",
    "statement_df = df.loc[df[\"labels\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c62f7bd3-1558-4bdf-b200-5b1067997f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78479"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_size = min(len(question_df), len(statement_df))\n",
    "min_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b69e618-d2ef-4bd8-9e71-aed875c12370",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df = question_df.iloc[:min_size]\n",
    "statement_df = statement_df.iloc[:min_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6d3a7c3-b6b5-4b73-b2c9-dc0ac447507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78479\n",
      "78479\n"
     ]
    }
   ],
   "source": [
    "print(len(question_df))\n",
    "print(len(statement_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc28bef5-b44f-497e-90af-a4c62c85bdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>is that Birmingham New Street</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>do you hold a current debit or credit card</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>do you have a rail card</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>would you like smoking or non-smoking</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>and  do you have any seat preference</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text  labels\n",
       "42               is that Birmingham New Street        1\n",
       "43  do you hold a current debit or credit card        1\n",
       "44                     do you have a rail card        1\n",
       "45       would you like smoking or non-smoking        1\n",
       "46        and  do you have any seat preference        1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([question_df, statement_df], axis = 0)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bdfb9b6-f797-4ef5-9c2b-6fb46ddca8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78479, 2)\n",
      "(156958, 2)\n"
     ]
    }
   ],
   "source": [
    "print(question_df.shape)\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9d9ad34-8259-4869-9b67-0543f06b0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3d032c6-8a3f-4fbe-b26d-63aefa286318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    78479\n",
       "1    78479\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1493f71c-2385-44a9-96a6-eae3cc1dbb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = merged_df.iloc[:dataset_size]\n",
    "df_small = df_small.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d63c4988-f1dd-44ca-beda-dc4096411f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "1    529\n",
       "0    471\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1103fa67-935b-4622-8095-0182d56bbb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2180bc5f-5f1b-40dd-bf38-8e1968ca9967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, or WUSTL) is a private research university l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does SDTV stand for?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What type of moraines are formed at the begini...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There was a constant power struggle between th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two groups of invertebrates have notably compl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  , or WUSTL) is a private research university l...       0\n",
       "1                          What does SDTV stand for?       1\n",
       "2  What type of moraines are formed at the begini...       1\n",
       "3  There was a constant power struggle between th...       1\n",
       "4  Two groups of invertebrates have notably compl...       0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83ad5e57-ecac-4562-a9ca-ebb9310aa3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df_small).train_test_split(test_size=0.10)\n",
    "# dataset_train_and_validation = dataset[\"train\"].train_test_split(test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90a3ad6c-64a2-4496-8ac3-7187058aeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\"train\": dataset[\"train\"], \"validation\": dataset[\"test\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b79061fc-004f-4f58-a70f-df13bd374e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74af24d8-7886-4824-a907-4900b083403f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "1    480\n",
       "0    420\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict[\"train\"].to_pandas().labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3a2ae5b-f050-4dfc-8f1a-6e9fdb0156a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dict[\"test\"].to_pandas().labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98fda20d-f229-467b-9908-d09b58bc75fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': [\"Marvel held its own comic book convention, Marvelcon '75, in spring 1975, and promised a Marvelcon '76. What marvel character was announced at the first Marvelcon\",\n",
       "  ' In addition, the club reached the final of the 1999–2000 UEFA Cup (losing on penalties to Galatasaray), were victorious in the 2003 and 2005 FA Cups, and won the Premier League in 2003–04 without losing a single match, an achievement which earned the side the nickname \"The Invincibles\"',\n",
       "  'Following the crusades which country was dominated',\n",
       "  'When did Miss America Sharlene Johnson graduate?',\n",
       "  'What control can be used while targeting that allows the player to forego manual targeting',\n",
       "  \"In 1718, at the behest of either Rector Samuel Andrew or the colony's Governor Gurdon Saltonstall, Cotton Mather contacted a successful businessman named Elihu Yale, who lived in Wales but had been born in Boston and whose father, David, had been one of the original settlers in New Haven, to ask him for financial help in constructing a new building for the college. What was Elihu Yale's father's name\",\n",
       "  ' Updates are not issued for older versions of Microsoft Windows.',\n",
       "  ' The International Monetary Fund found that \"advanced\" economies accounted for only 31% of global GDP while emerging and developing economies accounted for 69% of global GDP from 2007 to 2014',\n",
       "  ' Built by Ferranti, it was delivered to the University of Manchester in February 1951.',\n",
       "  'Greece is home to the first advanced civilizations in Europe and is considered the birthplace of Western civilization,[citation clutter] beginning with the Cycladic civilization on the islands of the Aegean Sea at around 3200 BC, the Minoan civilization in Crete (2700–1500 BC), and then the Mycenaean civilization on the mainland (1900–1100 BC). The Mycenaean civilization deteriorated in what time period '],\n",
       " 'labels': [1, 0, 1, 1, 1, 1, 0, 0, 0, 1]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "606bfb06-c0c9-4c87-a4e4-087e7378291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 768, 768)          23440896  \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               347600    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,788,597\n",
      "Trainable params: 23,788,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load model tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "vocabulary_size = 30522\n",
    "embedding_dimension = 768\n",
    "# min_len = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_dimension, input_length=embedding_dimension))\n",
    "model.add(LSTM(100)) #Can be same as embedding_dimension, but model will large and inefficient\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "# load model with binary classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d981702-e3c5-4fa7-9fd0-61d147c17334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e1ebe16d-0c3c-4386-a38a-1577c920798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [name for name, param in model.base_model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a7a93-6e43-492c-b9b5-f7a67c07d08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3158243c-dd02-41dd-89e9-f57353701a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████| 900/900 [00:00<00:00, 5521.99 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 2565.53 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# define text preprocessing\n",
    "def preprocess_function(examples):\n",
    "    # return tokenized text with truncation\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "    # return tokenizer(examples[\"text\"], truncation=False)\n",
    "\n",
    "#padded_dataset = sequence.pad_sequences(X_train, maxlen=min_len)\n",
    "# preprocess all datasets\n",
    "tokenized_data_raw = dataset_dict.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4dbdf664-5cf0-4da1-aa10-eaa6c2a9db4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8b17457-0851-4b73-bc14-5aa60a290293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marvel held its own comic book convention, Mar...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 8348, 2218, 2049, 2219, 5021, 2338, 4680...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In addition, the club reached the final of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1999, 2804, 1010, 1996, 2252, 2584, 1996...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Following the crusades which country was domin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2206, 1996, 16282, 2015, 2029, 2406, 200...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When did Miss America Sharlene Johnson graduate?</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2043, 2106, 3335, 2637, 21146, 20927, 26...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What control can be used while targeting that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2054, 2491, 2064, 2022, 2109, 2096, 1412...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels  \\\n",
       "0  Marvel held its own comic book convention, Mar...       1   \n",
       "1   In addition, the club reached the final of th...       0   \n",
       "2  Following the crusades which country was domin...       1   \n",
       "3   When did Miss America Sharlene Johnson graduate?       1   \n",
       "4  What control can be used while targeting that ...       1   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 8348, 2218, 2049, 2219, 5021, 2338, 4680...   \n",
       "1  [101, 1999, 2804, 1010, 1996, 2252, 2584, 1996...   \n",
       "2  [101, 2206, 1996, 16282, 2015, 2029, 2406, 200...   \n",
       "3  [101, 2043, 2106, 3335, 2637, 21146, 20927, 26...   \n",
       "4  [101, 2054, 2491, 2064, 2022, 2109, 2096, 1412...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2                     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "3               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = tokenized_data_raw[\"train\"].to_pandas()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8059f38-1aa2-497e-886d-b67017442fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.asarray(sequence.pad_sequences(df_train[\"input_ids\"], maxlen=embedding_dimension))\n",
    "target_data = np.asarray(df_train[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea8fdb67-23fa-449a-9c20-b60a7b965573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8485896-6bf8-4dbd-9e48-38fdda4d38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pad_tokens(collection__):\n",
    "#     # return [sequence.pad_sequences([x[\"input_ids\"]], maxlen=embedding_dimension, padding='post')[0] for x in collection__]\n",
    "#     return [sequence.pad_sequences([x[\"input_ids\"]], maxlen=embedding_dimension, padding='post')[0] for x in collection__]\n",
    "# def pad_collection(coll):\n",
    "#     padded_tokens = {}\n",
    "#     for key, v in tokenized_data.items():\n",
    "#         padded_tokens[key] = []\n",
    "#         # print(key)\n",
    "#         mapped = pad_tokens(v)\n",
    "#         for m in mapped:\n",
    "#             # print(m)\n",
    "#             padded_tokens[key].append(m)\n",
    "#     return padded_tokens\n",
    "# padded = pad_tokens(tokenized_data_raw[\"train\"][0][\"input_ids\"])\n",
    "# padded = pad_tokens(tokenized_data_raw[\"train\"])\n",
    "# padded\n",
    "    # for x in v:\n",
    "    #     print(x[\"input_ids\"])\n",
    "    #     print(sequence.pad_sequences([x[\"input_ids\"]], maxlen=embedding_dimension, padding='post'))\n",
    "    # print(sequence.pad_sequences([v[0][\"input_ids\"]], maxlen=embedding_dimension, padding='post'))\n",
    "# tokenized_data_padded = tokenized_data.map(lambda ds: sequence.pad_sequences(ds[\"input_ids\"], maxlen=embedding_dimension, padding='post'))\n",
    "# tokenized_data_padded = tokenized_data.map(pad_tokens)\n",
    "# tokenized_data_padded\n",
    "# padded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5affbad1-6fb0-4cb4-8dee-6806e3c9780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_data_padded = pad_collection(tokenized_data_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "401ed844-41db-4d13-a8e3-6b53367bfc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_data_raw[\"test\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea4dbe73-0d8f-4d4e-b35b-bdb0c73d24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_data_padded = DatasetDict(tokenized_data_padded)\n",
    "# tokenized_data_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fd37a7fd-af34-4d01-8dc5-aab033b6a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = tokenized_data_padded[\"train\"]\n",
    "# testing_data = tokenized_data_padded[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9725e8ec-bbbc-45d4-9d62-de8916ff6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "647ddef3-2019-4fe7-85a0-86dd9342a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_data[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0ce54b2c-3745-4440-b9cc-9e9f84729291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "auc_score = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # get predictions\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # apply softmax to get probabilities\n",
    "    probabilities = np.exp(predictions) / np.exp(predictions).sum(-1, \n",
    "                                                                 keepdims=True)\n",
    "    # use probabilities of the positive class for ROC AUC\n",
    "    positive_class_probs = probabilities[:, 1]\n",
    "    # compute auc\n",
    "    auc = np.round(auc_score.compute(prediction_scores=positive_class_probs, \n",
    "                                     references=labels)['roc_auc'],3)\n",
    "    \n",
    "    # predict most probable class\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    # compute accuracy\n",
    "    acc = np.round(accuracy.compute(predictions=predicted_classes, \n",
    "                                     references=labels)['accuracy'],3)\n",
    "    \n",
    "    return {\"Accuracy\": acc, \"AUC\": auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8f083512-7970-44d6-9fde-385e0cbe0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, target_data, test_size=0.2, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5f8ce304-207d-46a5-a62c-55980dee9193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ..., 13142,  1012,   102],\n",
       "       [    0,     0,     0, ...,  2185,  1029,   102],\n",
       "       [    0,     0,     0, ...,  2012, 10064,   102],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  2103,  6537,   102],\n",
       "       [    0,     0,     0, ...,  1999,  4885,   102],\n",
       "       [    0,     0,     0, ...,  3956,  1029,   102]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3e9b4da6-d31b-4d8d-837f-a891fdaeb90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "90/90 [==============================] - 39s 160ms/step - loss: 0.3669 - accuracy: 0.8417\n",
      "Epoch 2/5\n",
      "90/90 [==============================] - 14s 150ms/step - loss: 0.0299 - accuracy: 0.9917\n",
      "Epoch 3/5\n",
      "90/90 [==============================] - 14s 150ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "90/90 [==============================] - 13s 149ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "90/90 [==============================] - 14s 151ms/step - loss: 4.2695e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x180ce541ba0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "074f4e03-48fc-48c9-b931-3cc4027be27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_location):\n",
    "    save_classifier = open(model_location, \"wb\")\n",
    "    pickle.dump(model, save_classifier)\n",
    "    save_classifier.close()\n",
    "\n",
    "def load_model(model_location):\n",
    "    loaded_model = load_model(model_location)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f47410a9-a16e-4b87-a0da-0da414ced4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://845cbd35-be4d-4e9e-b787-64376455d077/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://845cbd35-be4d-4e9e-b787-64376455d077/assets\n"
     ]
    }
   ],
   "source": [
    "save_model(model, model_export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "672524a7-af8d-4cc0-8b8e-a78988e9da39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.944, 'AUC': 0.994}\n"
     ]
    }
   ],
   "source": [
    "# apply model to validation dataset\n",
    "predictions = model.predict(tokenized_data[\"validation\"])\n",
    "\n",
    "# Extract the logits and labels from the predictions object\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Use your compute_metrics function\n",
    "metrics = compute_metrics((logits, labels))\n",
    "print(metrics)\n",
    "\n",
    "# BERT {'Accuracy': 0.955, 'AUC': 0.989}\n",
    "#DistilBERT {'Accuracy': 0.944, 'AUC': 0.994}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "06a9f276-8aab-42cf-bffd-c17b4aeb10af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 81ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.05179006], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "47ed3425-ebd9-41b4-9e0d-8500db18b340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 77ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Extract the logits and labels from the predictions object\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m\n\u001b[0;32m      6\u001b[0m labels \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mlabel_ids\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Use your compute_metrics function\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'predictions'"
     ]
    }
   ],
   "source": [
    "# apply model to validation dataset\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Extract the logits and labels from the predictions object\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Use your compute_metrics function\n",
    "metrics = compute_metrics((logits, labels))\n",
    "print(metrics)\n",
    "\n",
    "# >> {'Accuracy': 0.889, 'AUC': 0.946}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "996388c7-a83d-4c50-8777-3cd7a8a25397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_text_single(text):\n",
    "    # return tokenized text with truncation\n",
    "    return tokenizer(text, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "10413eb8-533a-482c-a79d-d55242023fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2054, 2764, 2013, 1996, 26524, 19255, 16910, 1029, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"What developed from the mammalian odor pathways?\"\n",
    "# sentence = \"Could you please tell me the direction of the retaurant?\"\n",
    "# sentence = \"How do you know this?\"\n",
    "tokenized_question = tokenizer_text_single(sentence)\n",
    "tokenized_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8218e39b-ec8b-46e5-954b-2f04efb3ff54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-2.9417567,  3.1534703]], dtype=float32), label_ids=None, metrics={'test_model_preparation_time': 0.0017, 'test_runtime': 0.0693, 'test_samples_per_second': 14.435, 'test_steps_per_second': 14.435})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = trainer2.predict([tokenized_question])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8119f58d-2c69-4fe4-8f5f-35ef878868f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 9894, 2363, 1037, 3789, 1997, 4283, 2013, 1996, 7674, 2005, 2010, 2578, 1999, 1996, 12296, 3979, 1998, 2002, 3202, 5295, 2010, 2835, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Burke received a vote of thanks from the Commons for his services in the Hastings Trial and he immediately resigned his seat\"\n",
    "tokenized_question = tokenizer_text_single(sentence)\n",
    "tokenized_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0ca2942a-8408-4aff-9542-ac891ba07649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 1.7417043, -1.3585452]], dtype=float32), label_ids=None, metrics={'test_model_preparation_time': 0.0017, 'test_runtime': 0.0852, 'test_samples_per_second': 11.737, 'test_steps_per_second': 11.737})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = trainer2.predict([tokenized_question])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c91b5-211a-4e1f-9f88-40bc68a126df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_cuda",
   "language": "python",
   "name": "ml_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
